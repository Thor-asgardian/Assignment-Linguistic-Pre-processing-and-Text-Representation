# Assignment-Linguistic-Pre-processing-and-Text-Representation

Module â€“ 1:  Linguistic Pre-processing and Text Representation
1)	Introduction to NLP and Linguistic Essentials: syntax, semantics, morphology and pragmatics. 
2)	Text Pre-processing Techniques: tokenization, normalization, stop-word removal, stemming, lemmatization. 
3)	Part-of-Speech (POS) Tagging: rule-based and probabilistic methods. 
4)	Named Entity Recognition (NER): dictionary-based, CRF-based methods. N-gram Language Models: smoothing, backoff, and perplexity. 
5)	Classical Text Representations: Bag-of-Words (BoW), TF-IDF. 
6)	Word Embedding Techniques: Word2Vec (CBOW, Skip-gram), GloVe, FastText. 
7)	Comparison of classical and distributed word representations.

Lab Programs

1)	Text Preprocessing: Tokenization, stop-word removal, lemmatization, POS tagging, NER. Tools: spaCy, NLTK
2)	Word Representation Techniques: Compute BoW and TF-IDF vectors for a corpus. Compare with GloVe/Word2Vec embeddings. Tools: scikit-learn, genism.
